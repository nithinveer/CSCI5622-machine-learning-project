{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VaderSentiment is used for analysing the sentiment of the user review and also to assign the label to a review. In the below example, a hotel has five reviews. So VaderSentiment returns the intensity of negative,positive and neutral words in the review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.044, 'neu': 0.922, 'pos': 0.034, 'compound': -0.0951}\n",
      "{'neg': 0.0, 'neu': 0.671, 'pos': 0.329, 'compound': 0.945}\n",
      "{'neg': 0.037, 'neu': 0.716, 'pos': 0.247, 'compound': 0.8442}\n",
      "{'neg': 0.0, 'neu': 0.702, 'pos': 0.298, 'compound': 0.8834}\n",
      "{'neg': 0.0, 'neu': 0.688, 'pos': 0.312, 'compound': 0.9274}\n",
      "[['721061473', -1], ['721033945', 1], ['720401523', 1], ['720273596', 1], ['718936199', 1]]\n"
     ]
    }
   ],
   "source": [
    "v = []\n",
    "with open(r'C:\\Users\\dell\\CSCI5622-machine-learning-project-master\\TA-Data\\100021.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    #print(data['latitude'])\n",
    "    #print(data['reviews'])\n",
    "    for d in data['reviews']:\n",
    "        vl = []\n",
    "        #print(d['trip_type'])\n",
    "        #print(d['id'])\n",
    "        analyser = SentimentIntensityAnalyzer()\n",
    "        v1 = analyser.polarity_scores(d['text'])\n",
    "        print(v1)\n",
    "        if v1['compound']>0.05:\n",
    "            vl.append(d['id'])\n",
    "            #vl.append(d['trip_type'])\n",
    "            vl.append(1)\n",
    "        elif v1['compound']<-0.05:\n",
    "            vl.append(d['id'])\n",
    "            #vl.append(d['trip_type'])\n",
    "            vl.append(-1)\n",
    "        #print(len(d['text']))\n",
    "        v.append(vl)\n",
    "        #print(v1)\n",
    "    \n",
    "        #print(d['text'])\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_list = ['published_date','rating','latitude','longitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here StanfordCoreNLP is used for extracting features from reviews. When going through the training data, we observed that most of them have not rated on the individual components. So it is our job to extract the features from the review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    " res = nlp.annotate(\"Service and Location is good. Food is very bad.\",\n",
    "                    properties={\n",
    "                        'annotators': 'sentiment',\n",
    "                        'outputFormat': 'json',\n",
    "                        'timeout': 1000,\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 'Service and Location is good .': 3 Positive\n",
      "1: 'Food is very bad .': 1 Negative\n"
     ]
    }
   ],
   "source": [
    "for s in res[\"sentences\"]:\n",
    "     print(\"%d: '%s': %s %s\" % (\n",
    "         s[\"index\"],\n",
    "         \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "         s[\"sentimentValue\"], s[\"sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "pos_list = []\n",
    "for i in range(len(res[\"sentences\"])):\n",
    "    \n",
    "    for word in res[\"sentences\"][i][\"tokens\"]:\n",
    "        #print(word)\n",
    "        pos_list.append(word[\"pos\"])\n",
    "        pos.append('{}'.format(word[\"word\"]))\n",
    "    \n",
    "sent = \" \".join(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some basic regex operation in order to avoid the space that is inserted after the last word in a sentence and before the punctuation mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'CC', 'NNP', 'VBZ', 'JJ', '.', 'NNP', 'VBZ', 'RB', 'JJ', '.']\n",
      "['NNP', 'CC', 'NNP', 'VBZ', 'JJ', 'NNP', 'VBZ', 'RB', 'JJ']\n",
      "Service and Location is good. Food is very bad.\n",
      "['Service and Location is good', ' Food is very bad', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#print(pos)\n",
    "print(pos_list)\n",
    "fin_pos = []\n",
    "for i in pos_list:\n",
    "    if i!='.':\n",
    "        fin_pos.append(i)\n",
    "print(fin_pos)\n",
    "#print(sent)\n",
    "s1 = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', sent)\n",
    "print(s1)\n",
    "sent_list = s1.split('.')\n",
    "print(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Service and Location is good', ' Food is very bad']\n"
     ]
    }
   ],
   "source": [
    "sent_list_1 = sent_list[:len(sent_list)-1]\n",
    "print(sent_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for i in range(len(sent_list_1)):\n",
    "    word_list.append(sent_list_1[i].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Service', 'and', 'Location', 'is', 'good'], ['', 'Food', 'is', 'very', 'bad']]\n"
     ]
    }
   ],
   "source": [
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Service', 'and', 'Location', 'is', 'good'], ['Food', 'is', 'very', 'bad']]\n"
     ]
    }
   ],
   "source": [
    "word_fin_list = []\n",
    "\n",
    "for i in range(len(word_list)):\n",
    "    word_int_list = []\n",
    "    for j in range(len(word_list[i])):\n",
    "        if word_list[i][j]!='':\n",
    "            word_int_list.append(word_list[i][j])\n",
    "    #print(word_int_list)\n",
    "    word_fin_list.append(word_int_list)\n",
    "print(word_fin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NNP', 'CC', 'NNP', 'VBZ', 'JJ'], ['NNP', 'VBZ', 'RB', 'JJ']]\n"
     ]
    }
   ],
   "source": [
    "initial_index = 0\n",
    "pos_fin_list = []\n",
    "for i in range(len(word_list)):\n",
    "    le = len(word_list[i])\n",
    "    pos_fin_list.append(fin_pos[initial_index:initial_index+le])\n",
    "    \n",
    "    initial_index = le\n",
    "    #print(in)\n",
    "print(pos_fin_list)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "index_start = 0\n",
    "for i in range(len(word_fin_list)):\n",
    "    for j in range(len(word_fin_list[i])):\n",
    "        if pos_fin_list[i][j]=='NNP':\n",
    "            #print(i,j)\n",
    "            #print(word_list[i][j])\n",
    "            \n",
    "            for k in range(j,len(word_fin_list[i])):\n",
    "                #print(i,k)\n",
    "                if pos_fin_list[i][k]=='JJ':\n",
    "                    feature_list.append(word_fin_list[i][j])\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Service', 'Location', 'Food']\n"
     ]
    }
   ],
   "source": [
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving Forward, we are planning on getting the feature value by inputting the sentences to VaderSentiment and applying a weighted measure in order to arrive at the feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.6369}\n"
     ]
    }
   ],
   "source": [
    "a1 = SentimentIntensityAnalyzer()\n",
    "scores = a1.polarity_scores(\"Service and Location is best\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45189166666666664"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*scores['pos']+1.5*scores['neu']+1.5*scores['compound']+1*scores['neg'])/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-0.1: Value for feature:1<br>\n",
    "0.1-0.2: Value for feature:2<br>\n",
    "0.2-0.35: Value for feature:3<br>\n",
    "0.35-0.45: Value for feature:4<br>\n",
    "0.45+: Value for feature:5<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
