{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lokin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/lokin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from gensim.models import Word2Vec\n",
    "import sklearn\n",
    "import nltk\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from extract_from_es import getData\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning text in reviews\n",
    "def cleaning_reviews(hotel_id, reviews):\n",
    "    clean_reviews = {}\n",
    "    to_delete = set(string.punctuation) - {'.'}\n",
    "    string_punc = \"\".join(to_delete)\n",
    "    clean_reviews[hotel_id]= {}\n",
    "#     print(reviews.keys())\n",
    "    for key in reviews.keys():\n",
    "        text = str(reviews[key]).split()\n",
    "        table = str.maketrans('', '', string_punc)\n",
    "        stripped_punctuation = [w.translate(table) for w in text]\n",
    "        normalize_to_lower = [w.lower() for w in stripped_punctuation]\n",
    "        clean_words = [x for x in normalize_to_lower if not re.match(\"[0-9]\", x)]\n",
    "        clean_sent = ' '.join(clean_words)\n",
    "        clean_reviews[hotel_id][key] = clean_sent\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break review text into sentences by fullstop\n",
    "def reviews_into_sentences(cleaned_reviews):\n",
    "    for key in cleaned_reviews.keys():\n",
    "            sentence_filter = []\n",
    "            sentences = str(cleaned_reviews[key]).split(\".\")\n",
    "            for sentence in sentences:\n",
    "                if sentence!='':\n",
    "                    sentence = sentence.strip()\n",
    "                    sentence_filter.append(sentence)\n",
    "                    cleaned_reviews[key] = sentence_filter\n",
    "    return cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment(cleaned_reviews):\n",
    "    a1 = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = {}\n",
    "    for key in cleaned_reviews.keys():\n",
    "        sentiment_scores[key] = {}\n",
    "        for sent_index, sentence in enumerate(cleaned_reviews[key]):\n",
    "            scores = a1.polarity_scores(sentence)\n",
    "            sentiment_scores[key][sent_index] = scores\n",
    "    return sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(cleaned_reviews, sentiment_scores):\n",
    "    sentences_features = {}\n",
    "    for key in cleaned_reviews.keys():\n",
    "        sentences_features[key] = {}\n",
    "        fet_lst = []\n",
    "        for sentence_index, sentence in enumerate(cleaned_reviews[key]):\n",
    "            feature_list = []\n",
    "            word_tokens = nltk.word_tokenize(sentence)\n",
    "            result = nltk.pos_tag(word_tokens)\n",
    "            pos_tag_list, word_list, word_fin_list, pos_tag_fin_list = [],[],[],[]\n",
    "            for i in range(len(result)):\n",
    "                pos_tag_list.append(result[i][1])\n",
    "                word_list.append(result[i][0])\n",
    "            word_fin_list.append(word_list)\n",
    "            pos_tag_fin_list.append(pos_tag_list)\n",
    "            for w in range(len(word_fin_list)):\n",
    "                for j in range(len(word_fin_list[w])):\n",
    "                    if pos_tag_fin_list[w][j]=='NN':\n",
    "                        for k in range(j+1,len(word_fin_list[w])):\n",
    "                            if pos_tag_fin_list[w][k]=='CC':\n",
    "                                break\n",
    "                            if pos_tag_fin_list[w][k]=='JJ':\n",
    "                                feature_list.append(word_fin_list[w][j])\n",
    "                                break\n",
    "                        sentences_features[key][sentence_index] = feature_list\n",
    "                        fet_lst.append(feature_list)\n",
    "        sentences_features[key][\"feature_list\"] = fet_lst\n",
    "    return sentences_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_features(sentences_features):\n",
    "    unique_features = {}\n",
    "    for key in sentences_features.keys():\n",
    "        unique_features[key] = {}\n",
    "#         print(key)\n",
    "        feat = sentences_features[key][\"feature_list\"]\n",
    "        fet_lst = []\n",
    "        fet_set = set()\n",
    "        temp= []\n",
    "        for each_ in feat:\n",
    "            temp_str = \"\".join(each_)\n",
    "            if temp_str not in fet_set:\n",
    "                temp.append(each_)\n",
    "                fet_set.add(temp_str)\n",
    "        unique_features[key][\"feature_list\"] = temp\n",
    "    return unique_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_vec_hotel(hotel_id, unique_features):\n",
    "    data_month = hotel_features = {}\n",
    "    hotel_features[hotel_id] = {}\n",
    "    for key in unique_features.keys():\n",
    "        md = Word2Vec(unique_features[key][\"feature_list\"],min_count=1)\n",
    "        words_ = list(md.wv.vocab)\n",
    "        word2vec = {}\n",
    "        for feat_name in unique_features[key][\"feature_list\"]:\n",
    "            for f in feat_name:\n",
    "                if f in md.wv.vocab:\n",
    "                    word2vec[f] = md[f]\n",
    "        data_month[key] = pd.DataFrame.from_dict(word2vec)\n",
    "    hotel_features[hotel_id] = data_month\n",
    "    return hotel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "hotel_ids = [\"611947\",\"1418811\",\"111428\",\"84217\"]\n",
    "hotel_data = {}\n",
    "for ids in hotel_ids:   \n",
    "    reviews = getData(ids)\n",
    "    cleaned_reviews = cleaning_reviews(ids,reviews)\n",
    "    review_sentences = reviews_into_sentences(cleaned_reviews[ids])\n",
    "    sentiment_scores_sentence = calculate_sentiment(review_sentences)\n",
    "    sentences_features = find_features(review_sentences, sentiment_scores_sentence)\n",
    "    unique_sentence_features = get_unique_features(sentences_features)\n",
    "    hotel_features = word_to_vec_hotel(ids, unique_sentence_features)\n",
    "    hotel_data[ids] = hotel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['611947', '1418811', '111428', '84217'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['beverage', 'accent', 'david', 'recognition', 'program', 'hotel',\n",
       "       'beach', 'staff', 'care', 'pool', 'resort', 'fee', 'bonus', 'marriott',\n",
       "       'bonoy', 'energy', 'life', 'sheraton', 'sand', 'key', 'fun', 'sun',\n",
       "       'please', 'thank', 'time', 'dose', 'happiness', 'part', 'sunshine',\n",
       "       'beauty', 'side', 'park', 'mixture', 'playground', 'place', 'work',\n",
       "       'environment', 'joy', 'stay', 'experience', 'cabanas', 'charge',\n",
       "       'concession', 'day', 'usage', 'tranquil', 'island', 'location',\n",
       "       'traffic', 'era', 'relaxation', 'therapy', 'interaction', 'view',\n",
       "       'floor', 'fire', 'pit', 'vacation', 'bustle', 'property', 'person', 'i',\n",
       "       'something', 'conference', 'parking', 'opt', 'room', 'â€™', 's',\n",
       "       'complaint', 'size', 'welcoming', 'transportation', 'information',\n",
       "       'fitness', 'center', 'delight', 'tub'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_data['84217']['February'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['york', 'hilton', 'director', 'hotel', 'feel', 'everyone', 'money',\n",
       "       'resort', 'fee', 'majority',\n",
       "       ...\n",
       "       'breakfast', 'distance', 'radio', 'return', 'rappor', 'property', 'man',\n",
       "       'ny', 'need', 'coffe'],\n",
       "      dtype='object', length=153)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_data['611947']['February'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
